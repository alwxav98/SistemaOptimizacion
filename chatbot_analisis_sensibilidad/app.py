from flask import Blueprint, render_template, request, redirect, url_for, session
import openai
import os
import pytesseract
import re
import numpy as np
import json
from PIL import Image
from dotenv import load_dotenv
import cv2

# Cargar variables de entorno
load_dotenv()

# API Key de OpenRouter
#openrouter_api_key = os.getenv("OPENROUTER_API_KEY")

#if not openrouter_api_key:
    #raise ValueError("‚ùå ERROR: No se encontr√≥ la clave API de OpenRouter. Verifica tu archivo .env.")
openrouter_api_key = "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"
# Configurar cliente OpenRouter
client = openai.OpenAI(
    api_key=openrouter_api_key,
    base_url="https://openrouter.ai/api/v1"
)

# Crear Blueprint para chatbot
chatbot = Blueprint("chatbot", __name__, template_folder="templates", static_folder="static")

# Expresiones regulares para capturar n√∫meros en la tabla
NUMERIC_PATTERN = r"\d+\.\d+|\d+"

# Palabras clave relacionadas con Programaci√≥n Lineal
KEYWORDS = [
    "soluci√≥n √≥ptima", "valor √≥ptimo", "variable", "reduced cost", "slack",
    "surplus", "dual price", "maximizar", "restricci√≥n", "holgura", "costo",
    "artificial", "base", "coeficiente", "an√°lisis de sensibilidad"
]

def extraer_texto_desde_imagen(image_file):
    """Extrae texto de una imagen utilizando OCR."""
    try:
        image = Image.open(image_file)
        image = np.array(image)
        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
        _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY_INV)
        extracted_text = pytesseract.image_to_string(thresh)
        
        texto_filtrado = []
        for line in extracted_text.split("\n"):
            if any(kw in line.lower() for kw in KEYWORDS) or re.search(NUMERIC_PATTERN, line):
                texto_filtrado.append(line.strip())
        
        texto_final = "\n".join(texto_filtrado)
        return texto_final if texto_final.strip() else None
    except Exception as e:
        print(f"‚ùå Error procesando la imagen: {str(e)}")
        return None

@chatbot.route("/")
def index():
    return redirect(url_for("chatbot.chat"))

@chatbot.route("/chat", methods=["GET", "POST"])
def chat():
    if request.method == "GET":
        session.pop("historial", None)  # üî• Borra la sesi√≥n al entrar nuevamente
    
    if "historial" not in session:
        session["historial"] = []
    
    full_prompt = ""

    # üìå Datos desde solucion.html
    if request.method == "POST" and "solucion" in request.form:
        try:
            solucion = json.loads(request.form["solucion"])
            variables_holgura_exceso = json.loads(request.form["variables_holgura_exceso"])
            nombres_variables = json.loads(request.form.get("nombres_variables", "{}"))  # Cargar nombres personalizados
            
            full_prompt = "*üìä An√°lisis de Sensibilidad*\n\n"
            full_prompt += "*Soluci√≥n √ìptima:*\n"
            for key, val in solucion.items():
                nombre_variable = nombres_variables.get(key, key)
                full_prompt += f"{nombre_variable} = {val}\n"
            
            full_prompt += "\n*Variables de Holgura/Exceso:*\n"
            for key, val in variables_holgura_exceso.items():
                full_prompt += f"{key} = {val}\n"
            
            full_prompt += """
            üîç *Instrucciones para el An√°lisis:*
            - Analiza el impacto de las restricciones en la soluci√≥n √≥ptima.
            - Identifica qu√© restricciones limitan m√°s la producci√≥n.
            - Sugiere c√≥mo modificar restricciones o coeficientes para maximizar beneficios.
            - Explica si aumentar recursos en una restricci√≥n mejorar√≠a la soluci√≥n.
            """
        except json.JSONDecodeError as e:
            print(f"‚ùå Error al procesar JSON: {e}")
            return render_template("chat.html", historial=session["historial"], bot_respuesta="‚ùå Error en los datos recibidos.")
    
    # üìå Consulta manual del usuario
    if request.method == "POST" and "message" in request.form:
        user_input = request.form.get("message", "").strip()
        image_file = request.files.get("image")
        
        extracted_text = ""
        if image_file:
            texto_extraido = extraer_texto_desde_imagen(image_file)
            extracted_text = f"Datos extra√≠dos:\n{texto_extraido}" if texto_extraido else "‚ö†Ô∏è No se pudo extraer texto v√°lido de la imagen."
        
        full_prompt = f"{user_input}\n{extracted_text}".strip()
    
    if not full_prompt:
        return render_template("chat.html", historial=session["historial"], bot_respuesta="Por favor, ingrese un mensaje o suba una imagen v√°lida.")
    
    session["historial"].append({"user": full_prompt, "bot": "Procesando an√°lisis..."})
    session.modified = True
    
    # üìå Configuraci√≥n del modelo
    mensajes_previos = [
        {"role": "system", "content": """
        Eres un experto en Programaci√≥n Lineal y An√°lisis de Sensibilidad. 
        Analiza los datos proporcionados y genera recomendaciones detalladas sobre la optimizaci√≥n del sistema productivo. 
        Explica el impacto de las restricciones y coeficientes en la soluci√≥n √≥ptima.
        """}
    ]
    mensajes_previos.append({"role": "user", "content": full_prompt})
    
    try:
        print("üì® Enviando solicitud a OpenRouter...")
        respuesta = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            temperature=0.7,
            max_tokens=800,
            messages=mensajes_previos
        )
        
        bot_respuesta = respuesta.choices[0].message.content if respuesta.choices else "‚ö†Ô∏è No se recibi√≥ respuesta del modelo."
        session["historial"][-1]["bot"] = bot_respuesta
        session.modified = True  
    except Exception as e:
        print(f"‚ùå Error al procesar la solicitud: {str(e)}")
        return render_template("chat.html", historial=session["historial"], bot_respuesta=f"‚ùå Error en la solicitud: {str(e)}")
    
    return render_template("chat.html", historial=session["historial"])

def chat_analyze(problem_statement, solution, cost):
    """
    Env√≠a la soluci√≥n y el contexto al chatbot para an√°lisis de sensibilidad.
    """
    analysis_prompt = f"""
    {problem_statement}
    La soluci√≥n obtenida es {solution} con un costo de {cost}.
    ¬øPuedes realizar un an√°lisis de sensibilidad sobre esta soluci√≥n?
    """

    response = chatbot_response(analysis_prompt)
    return response

def chatbot_response(prompt):
    """
    Llama a OpenAI para generar la respuesta.
    """
    mensajes_previos = [
        {"role": "system", "content": """
        Eres un experto en redes y transporte. Eval√∫a la estabilidad de la soluci√≥n ante cambios en los costos o capacidades.
        """},
        {"role": "user", "content": prompt}
    ]

    try:
        respuesta = client.chat.completions.create(
            model="openai/gpt-3.5-turbo",
            temperature=0.7,
            max_tokens=500,
            messages=mensajes_previos
        )
        return respuesta.choices[0].message.content if respuesta.choices else "‚ö†Ô∏è No se recibi√≥ respuesta del modelo."
    except Exception as e:
        return f"‚ùå Error en la solicitud: {str(e)}"
